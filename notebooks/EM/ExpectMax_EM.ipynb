{
 "metadata": {
  "name": "",
  "signature": "sha256:2e88c87f9bf342aa5dbdb19ac03b6d9a1af76a2d052fd48e39dae060be0c8f79"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Expectation-Maximization: Sequential or simultaneous ?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So if I understood the question correctly the sequential update is defined as follows:\n",
      "The $x$ in the denominator of eq (1) is defined as (the $j$th component of the vector is updated)\n",
      "\n",
      "\\begin{equation}\n",
      "x_t = \n",
      "\\begin{cases}\n",
      "x_t^{(k+1)} & t < j \\\\\n",
      "x_t^{(k)} & else \\\\\n",
      "\\end{cases}\n",
      "\\end{equation}\n",
      "\n",
      "whereas the simultaneous version is defined as\n",
      "\\begin{equation}\n",
      "x_t = x_t^{(k)} \\quad \\forall t\n",
      "\\end{equation}\n",
      "\n",
      "\n",
      "I did not read the cited paper, but if the first definition would be the intended, my opinion is that it\n",
      "should definitely be stated explicitly. (And one should also chose a more explicit notation, like e.g using $\\tilde x^{k}$\n",
      "for the denominator $x$, since it is in a 'mixed' state).\\newline\n",
      "The good news however is that the sequential versus simultaneous update schema does not matter (at least not\n",
      "for the result), since if the algorithm converged ($x^{k+1} = x^{k}$), the difference in equation (1) will vanish and\n",
      "the two forms are equivalent. Another way to see this is to write the algorithm as\n",
      "\n",
      "\\begin{equation}\n",
      "x_j^{k+1} = x_j^{k} \\{ A^{T}[b \\oslash A \\tilde x^{k}] \\oslash A^{T} 1 \\}_j\n",
      "\\end{equation}\n",
      "where (as already defined)\n",
      "\\begin{equation}\n",
      "\\tilde x_t^{k} = \n",
      "\\begin{cases}\n",
      "x_t^{(k+1)} & t < j \\\\\n",
      "x_t^{(k)} & else \\\\\n",
      "\\end{cases}\n",
      "\\end{equation}\n",
      "\n",
      "Hence in the state converged, the state $\\tilde x^{k}$ in the curly bracket will not change anymore, no matter of the update schema.\n",
      "(Componentwise feedback or 'all in one' is irrelevant).\\newline\n",
      "So I guess it would not make sense to run a sequential update mode, since (at least in theory) it will result in the same\n",
      "limit but with quite a computational overhead. The only reason for (1) could be something like numerical stability\n",
      "or faster convergence rate  (intrinsic, not related to computational implementation), but this should then be\n",
      "emphasized in the paper.\\newline\n",
      "Tell me if you are not fully satisfied with the answer (I am neither ;), then as a next step I should read the paper.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Implementation Example"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "def em(A, b, N, eps, doSeq):\n",
      "    x = np.ones(A.shape[1])\n",
      "    c_1 = np.ones(A.shape[0])\n",
      "    c = np.dot(A.T,c_1)\n",
      "    for i in range(N):\n",
      "        x_old = np.copy(x)\n",
      "        if doSeq:\n",
      "            for k in range(x.shape[0]):\n",
      "                x[k] *= np.dot(A.T[k,:], b/A.dot(x))/c[k]\n",
      "        else:\n",
      "            x *= np.dot(A.T, b/A.dot(x))/c\n",
      "        e = ((x - x_old)**2).sum()/float(x.shape[0])\n",
      "        if e < eps:\n",
      "            print \"converged after\", i, \"steps\"\n",
      "            print \"should be ones\", np.dot(A.T, b/A.dot(x))/c\n",
      "            return x\n",
      "    print \"not converged at step\", i\n",
      "    print \"should be ones\", np.dot(A.T, b/A.dot(x))/c\n",
      "    return x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ps = 3 #problemsize\n",
      "#A needs not be symmteric for em, but for linalg\n",
      "A = np.random.random((ps,ps))\n",
      "b = np.random.random(ps)\n",
      "x_c = em(A, b, N=1000, eps=1.0e-9, doSeq=True)\n",
      "x_i = np.linalg.solve(A, b)\n",
      "print \"initial\", b\n",
      "print \"EM Algo\", A.dot(x_c)\n",
      "print \"LinAlg \", A.dot(x_i)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "converged after 105 steps\n",
        "should be ones [ 0.95025961  0.99998977  1.00000905]\n",
        "initial [ 0.60852186  0.39641059  0.58876238]\n",
        "EM Algo [ 0.72227996  0.37929145  0.49218088]\n",
        "LinAlg  [ 0.60852186  0.39641059  0.58876238]\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    }
   ],
   "metadata": {}
  }
 ]
}